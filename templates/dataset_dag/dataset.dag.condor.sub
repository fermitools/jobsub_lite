# Filename: dataset.dag.condor.sub
# Generated by jobsub_lite based on condor_submit_dag dataset.dag
universe	= scheduler
executable	= dagman_wrapper.sh
getenv		= True
output		= dataset.dag.lib.out
error		= dataset.dag.lib.err
log		= dataset.dag.dagman.log
transfer_input_files = {{",".join(transfer_files)}},dataset.dag.condor.sub
#remove_kill_sig	= SIGUSR1
+OtherJobRemoveRequirements	= "DAGManJobId =?= $(cluster)"
# Note: default on_exit_remove expression:
# ( ExitSignal =?= 11 || (ExitCode =!= UNDEFINED && ExitCode >=0 && ExitCode <= 2))
# attempts to ensure that DAGMan is automatically
# requeued by the schedd if it exits abnormally or
# is killed (e.g., during a reboot).
on_exit_remove	= (ExitSignal =?= 11 || (ExitCode =!= UNDEFINED && ExitCode >=0 && ExitCode <= 2))
copy_to_spool	= False
arguments       = "-p 0 -f -l . -Lockfile dataset.dag.lock -AutoRescue 1 -DoRescueFrom 0 -Dag dataset.dag -Suppress_notification -CsdVersion $CondorVersion:' '9.0.13' 'May' '26' '2022' 'PackageID:' '9.0.13-1.1' '$ -Dagman /usr/bin/condor_dagman"
environment	= _CONDOR_SCHEDD_ADDRESS_FILE=/var/lib/condor/spool/.schedd_address;_CONDOR_MAX_DAGMAN_LOG=0;_CONDOR_SCHEDD_DAEMON_AD_FILE=/var/lib/condor/spool/.schedd_classad;_CONDOR_DAGMAN_LOG=dataset.dataset.dagman.out;_condor_SEC_CLIENT_AUTHENTICATION_METHODS=FS;_condor_SEC_CREDENTIAL_STORER=/bin/true

+JobsubClientDN="{{clientdn}}"
+JobsubClientIpAddress="{{ipaddr}}"
+Owner="{{user}}"
+JobsubServerVersion="{{jobsub_version}}"
+JobsubClientVersion="{{jobsub_version}}"
+JobsubClientKerberosPrincipal="{{kerberos_principal}}"

{{lines|join("\n")}}

{% if subgroup is defined and subgroup %}
+AccountingGroup = "group_{{group}}.{{subgroup}}.{{user}}"
{% else %}
+AccountingGroup = "group_{{group}}.{{user}}"
{% endif %}

+Jobsub_Group="{{group}}"
+JobsubJobId="$(CLUSTER).$(PROCESS)@{{schedd}}"

{% if role is defined and role and role != 'Analysis' %}
use_oauth_services = {{group}}_{{role}}
{% else %}
use_oauth_services = {{group}}
{% endif %}

queue
